---
title: "Why Choose IoTeX AI Gateway"
description: "Key benefits of using IoTeX AI Gateway for your AI applications"
---

<CardGroup cols={2}>
  <Card title="OpenAI-Compatible" icon="plug">
    Uses the standard OpenAI API format. Drop in your existing code and just change the base URL and API key.
  </Card>
  <Card title="Many Models, One API" icon="brain">
    Access models from Google, DeepSeek, Meta, Qwen, Mistral, and more through a single endpoint.
  </Card>
  <Card title="Reliable & Secure" icon="shield-check">
    Load balancing, automatic failover, encrypted transmission, and API key authentication.
  </Card>
  <Card title="Cost Optimized" icon="coins">
    Transparent pricing with no hidden fees. Compare models and pick the best cost-performance ratio.
  </Card>
</CardGroup>

## OpenAI SDK Compatibility

If you're already using the OpenAI SDK, switching to IoTeX AI Gateway takes two lines of code:

```python
from openai import OpenAI

client = OpenAI(
    api_key="your-iotex-api-key",          # Replace with your IoTeX API key
    base_url="https://gateway.iotex.ai/v1"  # Point to IoTeX AI Gateway
)

# Everything else stays the same
response = client.chat.completions.create(
    model="gemini-2.5-flash",
    messages=[{"role": "user", "content": "Hello!"}]
)
```
